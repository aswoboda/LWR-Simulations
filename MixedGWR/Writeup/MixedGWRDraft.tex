\documentclass{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{animate}
\title{Mixed GWR Simulation Write-up}
\author{Aaron Swoboda}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}


\begin{document}
\maketitle

What are our research questions? Basically:
\begin{enumerate}
\item Can we find the ``true'' model among the eight different possibilities with three model parameters?
\item Are there differences in the results based on the metric used?
\item What happens as we change the sample size and amount of error in the model?
\item How much does it really matter if we are concerned with coefficient estimates?
  \begin{itemize}
  \item How well does our selected model perform as measured by beta RMSE?
  \item Does our model perform better when we select the correct model?
  \item Can we control for whether we selected a model with the correct spatial variation for a given parameter?
  \end{itemize}
\item What about using bandwidth size as a dependent variable?
\item What happens when we use other decision tools to help with model selection? (Monte Carlo simulations and test statistics)
\end{enumerate}





\section{Methodology}

Imagine a simple linear model with two explanatory variables,
\begin{equation}
Y = \beta _0 + \beta _1 *X_1 + \beta _2 * X_2 + \epsilon
\end{equation}
Now imagine that each of our $N$ individual observations in this model occur at geographical locations on a Cartesian plane. Thus our data consists of an $N x 5$ matrix, where $Y$ may be house prices, $X_1$ and $X_2$ could be the living space and lot size associated with each house, and the final two columns determine the location of the observations (for instance, latitude and longitude, or distances north and east from a prescribed point serving as the origin).

The above simple model exemplifies spatial stationarity in the parameters. The $\beta$ coefficients are constant over space. Instead, the coefficients could exhibit spatial non-stationarity, in which case one, two, or all three of the $\beta$ coefficients are a function of location. This has a natural interpretation in the current real estate example. Location matters. Location can matter in different ways. For instance, if the value of land varies over space, then we would expect the coefficient on lot size to vary over space, while it is also possible that the intercept varies over space to reflect variation in prices of similar houses in different locations. 

While it is possible to parameterize the variation in coefficients, for instance researchers often (CITATION?) include a variable measuring the distance from an observation to an important amenity such as the Central Business District and then this distance variable could be interacted with variables whose value are predicted to vary over space. However, it is not implausible to believe that the variation in coefficients might not be easily parameterized (for instance, if land values are a non-monotonic function of distance). Researchers may instead interact variables with fixed effects for cities or census tracts. However, such strategies require the analyst to make assumptions that severely limit the type and degree of variation in the parameters. For instance, interaction terms with geographic boundaries assume discrete differences in the value of parameters across the boundaries, while instead the parameters may instead be a continuous function of location.

\subsection{Local Regression to the Rescue?}


\subsection{Experimental Design}

We generate data in the following format:
\begin{equation}
Y = \beta _0(location) + \beta _1(location) *X_1 + \beta _2(location) * X_2 + \epsilon ,
\end{equation}
where sometimes the coefficient is in fact stationary, $\beta _i(location) = \beta$, and other times it is non-stationary. With three coefficients each having the possibility of being stationary or not, there are eight different possible combinations, ranging from (stationary, stationary, stationary) to (non-stationary, non-stationary, non-stationary).

We generate data using all eight different combinations and then estimate all eight possible LWR models (assuming non-stationarity or not for each variable). We then calculate different Cross-Validation metrics and compare their values across models and bandwidths. 

We have three different values for each coefficient in our DGP, no variation, some variation, and more variation.

We also change the sample size of our data as well as the variance of the model error term.

\section{Simulation Results}

We have seven different ways to pick the ``best'' model (the AIC, GCV, SCV, LOOCV, and RMSEs for the three different coefficients). Here are tables showing the relative frequency (in percentage) that each model number was selected by optimizing a given metric. Note that the columns in the following tables may not sum exactly to 100 due to rounding.




\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwa{for} \hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{8}\hlstd{) \{}
    \hlstd{temp2} \hlkwb{=} \hlkwd{which}\hlstd{(mcOutput[,} \hlstr{"True Model"}\hlstd{, ]} \hlopt{==} \hlstd{i,} \hlkwc{arr.ind} \hlstd{=} \hlnum{TRUE}\hlstd{)}
    \hlstd{temp3} \hlkwb{=} \hlstd{mcOutput[}\hlnum{8}\hlopt{:}\hlnum{14}\hlstd{,} \hlstr{"Model Number"}\hlstd{,} \hlkwd{unique}\hlstd{(temp2[,} \hlnum{2}\hlstd{])]}
    \hlstd{temp4} \hlkwb{=} \hlkwd{factor}\hlstd{(temp3)}
    \hlstd{newdata} \hlkwb{=} \hlkwd{data.frame}\hlstd{(}\hlkwc{ModelNum} \hlstd{= temp4,} \hlkwc{Metric} \hlstd{=} \hlkwd{factor}\hlstd{(}\hlkwd{rownames}\hlstd{(temp3),}
        \hlkwc{levels} \hlstd{=} \hlkwd{rownames}\hlstd{(temp3)))}
    \hlkwd{cat}\hlstd{(}\hlkwd{paste}\hlstd{(}\hlstr{"\textbackslash{}n true model ="}\hlstd{, i,} \hlstr{"\textbackslash{}n"}\hlstd{))}
    \hlkwd{cat}\hlstd{(}\hlstr{"spatial variation...\textbackslash{}n"}\hlstd{)}
    \hlkwd{print}\hlstd{(models[i, ])}
    \hlkwd{print}\hlstd{(}\hlkwd{round}\hlstd{(}\hlkwd{table}\hlstd{(newdata)} \hlopt{*} \hlnum{100} \hlopt{*} \hlnum{7}\hlopt{/}\hlkwd{sum}\hlstd{(}\hlkwd{table}\hlstd{(newdata)),} \hlnum{0}\hlstd{))}
\hlstd{\}}
\end{alltt}
\begin{verbatim}
## 
##  true model = 1 
## spatial variation...
##   beta0 beta1 beta2
## 1    no    no    no
##         Metric
## ModelNum AIC GCV SCV LOOCV B0RMSE B1RMSE B2RMSE
##        1   0   0   0    75      6      7      6
##        2  26  26   0     6      5     22     20
##        3  34  33   0     6     21      4     22
##        4   1   1   8     2      5      3     37
##        5  38  38   0     7     20     21      4
##        6   1   1   8     2      5     35      3
##        7   1   1   5     1     32      4      5
##        8   0   0  78     0      5      3      2
## 
##  true model = 2 
## spatial variation...
##   beta0 beta1 beta2
## 2   yes    no    no
##         Metric
## ModelNum AIC GCV SCV LOOCV B0RMSE B1RMSE B2RMSE
##        1   0   0   0     4      0      4      4
##        2  91  91  37    89     94     29     29
##        3   4   4   0     2      1      6     25
##        4   0   1  16     1      1      1     32
##        5   4   4   0     3      1     24      6
##        6   0   1  16     1      1     33      1
##        7   0   0   3     0      1      2      2
##        8   0   0  28     0      0      1      1
## 
##  true model = 3 
## spatial variation...
##   beta0 beta1 beta2
## 3    no   yes    no
##         Metric
## ModelNum AIC GCV SCV LOOCV B0RMSE B1RMSE B2RMSE
##        1   0   0   0    12     13      0     13
##        2  11  11   1     7      1      2     24
##        3  77  76   0    65     23     66     22
##        4   2   2  12     4      4      6     32
##        5   8   8   0     5     24      2      1
##        6   0   0   9     1      2      3      2
##        7   2   2   6     5     29     15      3
##        8   0   0  72     1      4      6      2
## 
##  true model = 4 
## spatial variation...
##   beta0 beta1 beta2
## 4   yes   yes    no
##         Metric
## ModelNum AIC GCV SCV LOOCV B0RMSE B1RMSE B2RMSE
##        1   0   0   0     2      1      0      6
##        2  70  68  29    65     65      6     29
##        3  10   9   0     8      2     34     25
##        4  16  19  25    21     25     14     34
##        5   2   2   0     2      2      4      2
##        6   0   1  13     1      2      8      1
##        7   0   0   3     1      2     22      2
##        8   0   0  30     0      2     12      1
## 
##  true model = 5 
## spatial variation...
##   beta0 beta1 beta2
## 5    no    no   yes
##         Metric
## ModelNum AIC GCV SCV LOOCV B0RMSE B1RMSE B2RMSE
##        1   0   0   0    12     13     13      0
##        2  11  10   1     7      1     24      2
##        3   8   8   0     4     24      1      2
##        4   0   1   9     1      1      2      3
##        5  78  77   0    66     23     23     66
##        6   1   2  12     5      5     32      6
##        7   1   2   6     4     30      3     15
##        8   0   0  73     1      4      2      6
## 
##  true model = 6 
## spatial variation...
##   beta0 beta1 beta2
## 6   yes    no   yes
##         Metric
## ModelNum AIC GCV SCV LOOCV B0RMSE B1RMSE B2RMSE
##        1   0   0   0     2      1      6      0
##        2  71  68  29    66     65     30      7
##        3   3   2   0     2      2      2      4
##        4   0   0  13     1      2      1      7
##        5  10   9   0     8      2     24     34
##        6  16  19  24    20     25     33     14
##        7   0   1   3     1      2      2     21
##        8   0   0  30     0      2      1     13
## 
##  true model = 7 
## spatial variation...
##   beta0 beta1 beta2
## 7    no   yes   yes
##         Metric
## ModelNum AIC GCV SCV LOOCV B0RMSE B1RMSE B2RMSE
##        1   0   0   0     5     13      1      1
##        2   8   8   1     6      0      2      2
##        3  25  24   0    18     25     16      2
##        4   1   2   9     3      1     12      4
##        5  25  24   0    18     25      2     17
##        6   2   2   9     3      1      5     12
##        7  39  40   8    44     31     50     51
##        8   1   1  72     3      4     11     11
## 
##  true model = 8 
## spatial variation...
##   beta0 beta1 beta2
## 8   yes   yes   yes
##         Metric
## ModelNum AIC GCV SCV LOOCV B0RMSE B1RMSE B2RMSE
##        1   0   0   0     1      1      1      1
##        2  60  57  23    53     48      7      7
##        3   6   5   0     5      3     15      5
##        4   9  11  19    12     14     16      8
##        5   6   5   0     5      3      5     16
##        6   9  11  19    11     14      8     15
##        7   3   3   3     4      4     32     33
##        8   6   7  35     8     14     16     15
\end{verbatim}
\end{kframe}
\end{knitrout}


The results of the previous tables must be taken with a grain of salt, as there are frequently times when a ``true'' model may include variation in a coefficient, but the degree of non-stationarity in the coefficient may be small. In such cases, choosing an incorrect model (such as one that keeps such a coefficient constant) may not be such a big problem. 

Some patterns clearly emerge. 
\begin{itemize}
\item The AIC and GCV metrics \emph{never} select Model 1, even when it is the actual model.
\item There are several occasions where the model/bandwidth combination with the smallest RMSE is not the ``correct'' model.
\end{itemize}

\subsection{Coefficient Formulation}

Even if an incorrect model is chosen, the model may yield accurate estimates of the coefficients. In each run of the simulation we estimated 50 different model/bandwidth combinations (seven different bandwidths for each of the seven models with at least one coefficient varying over space, plus the standard OLS model). We calculate the Root Mean Squared Error for each model and can rank these values. For instance, it is possible, and often the case, that the ``wrong'' model yields the most accurate estimates of a coefficient among all of the models implemented.


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{colMat} \hlkwb{=} \hlkwd{matrix}\hlstd{(}\hlstr{"black"}\hlstd{,} \hlnum{8}\hlstd{,} \hlnum{3}\hlstd{)}
\hlstd{colMat[}\hlkwd{as.matrix}\hlstd{(models)} \hlopt{==} \hlstr{"yes"}\hlstd{]} \hlkwb{=} \hlstr{"red"}
\hlkwd{par}\hlstd{(}\hlkwc{oma} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{2}\hlstd{,} \hlnum{3}\hlstd{,} \hlnum{0}\hlstd{))}
\hlkwd{par}\hlstd{(}\hlkwc{mar} \hlstd{=} \hlkwd{rep}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{4}\hlstd{))}
\hlkwa{for} \hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{8}\hlstd{) \{}
    \hlcom{# i = 1}
    \hlkwd{layout}\hlstd{(}\hlkwd{matrix}\hlstd{(}\hlnum{1}\hlopt{:}\hlnum{12}\hlstd{,} \hlnum{4}\hlstd{,} \hlnum{3}\hlstd{,} \hlkwc{byrow} \hlstd{= T))}
    \hlstd{temp2} \hlkwb{=} \hlkwd{which}\hlstd{(mcOutput[}\hlnum{1}\hlstd{,} \hlstr{"True Model"}\hlstd{, ]} \hlopt{==} \hlstd{i)}
    \hlstd{inputMetrics} \hlkwb{=} \hlkwd{c}\hlstd{(}\hlstr{"AIC"}\hlstd{,} \hlstr{"GCV"}\hlstd{,} \hlstr{"SCV"}\hlstd{,} \hlstr{"LOOCV"}\hlstd{)}
    \hlstd{inputStats} \hlkwb{=} \hlkwd{c}\hlstd{(}\hlstr{"B0RMSE Rank"}\hlstd{,} \hlstr{"B1RMSE Rank"}\hlstd{,} \hlstr{"B2RMSE Rank"}\hlstd{)}
    \hlkwa{for} \hlstd{(j} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{4}\hlstd{) \{}
        \hlkwa{for} \hlstd{(k} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{3}\hlstd{) \{}
            \hlstd{temp3} \hlkwb{=} \hlstd{mcOutput[inputMetrics[j], inputStats[k], temp2]}
            \hlcom{# summary(temp3)}
            \hlkwd{hist}\hlstd{(temp3,} \hlkwc{xlim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{50}\hlstd{),} \hlkwc{breaks} \hlstd{=} \hlnum{5} \hlopt{*} \hlstd{(}\hlnum{0}\hlopt{:}\hlnum{10}\hlstd{),} \hlkwc{col} \hlstd{=} \hlkwd{ifelse}\hlstd{(colMat[i,}
                \hlstd{k]} \hlopt{==} \hlstr{"red"}\hlstd{,} \hlstr{"red"}\hlstd{,} \hlstr{"grey85"}\hlstd{),} \hlkwc{axes} \hlstd{= F,} \hlkwc{ylab} \hlstd{=} \hlstr{"rel freq"}\hlstd{,}
                \hlkwc{xlab} \hlstd{=} \hlstr{"rank"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{""}\hlstd{)}
        \hlstd{\}}
    \hlstd{\}}
    \hlkwd{mtext}\hlstd{(}\hlkwc{text} \hlstd{=} \hlkwd{paste0}\hlstd{(}\hlstr{"Model #"}\hlstd{, i,} \hlstr{"(non-stationary parameters in red"}\hlstd{),}
        \hlkwc{side} \hlstd{=} \hlnum{3}\hlstd{,} \hlkwc{outer} \hlstd{=} \hlnum{TRUE}\hlstd{,} \hlkwc{line} \hlstd{=} \hlnum{1.8}\hlstd{)}
    \hlkwd{mtext}\hlstd{(inputMetrics,} \hlkwc{at} \hlstd{=} \hlkwd{seq}\hlstd{(}\hlnum{0.875}\hlstd{,} \hlnum{0.125}\hlstd{,} \hlkwc{length.out} \hlstd{=} \hlnum{4}\hlstd{),} \hlkwc{side} \hlstd{=} \hlnum{2}\hlstd{,} \hlkwc{outer} \hlstd{= T)}
    \hlkwd{mtext}\hlstd{(}\hlkwd{paste0}\hlstd{(}\hlstr{"B"}\hlstd{,} \hlnum{0}\hlopt{:}\hlnum{2}\hlstd{),} \hlkwc{at} \hlstd{=} \hlkwd{seq}\hlstd{(}\hlnum{0.17}\hlstd{,} \hlnum{0.83}\hlstd{,} \hlkwc{length.out} \hlstd{=} \hlnum{3}\hlstd{),} \hlkwc{side} \hlstd{=} \hlnum{3}\hlstd{,}
        \hlkwc{outer} \hlstd{= T,} \hlkwc{line} \hlstd{=} \hlnum{0}\hlstd{,} \hlkwc{col} \hlstd{= colMat[i, ])}
\hlstd{\}}
\end{alltt}
\end{kframe}







\animategraphics[,autoplay,loop,controls]{0.5}{figure/BetaRankTabulations}{1}{8}

\end{knitrout}



\section{Accuracy of Beta Estimates}

During the experiment we calculated the Root Mean Squared Error the estimated coefficients for all models. We then ranked each model from smallest to largest RMSEs and collected the RMSE values and ranks for all models that minimized one of the model selection criteria and the model with the smallest RMSE for this coefficient. 

Let's see if there is a relationship between the RMSE values/ranks and the parameters we modified in the experiment.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# temp2 = which(mcOutput[1, 'True Model', ] == i) inputMetrics = c('AIC',}
\hlcom{# 'GCV', 'SCV', 'LOOCV') inputStats = c('B0RMSE Rank', 'B1RMSE Rank',}
\hlcom{# 'B2RMSE Rank') temp3 = mcOutput[inputMetrics[j], inputStats[k], temp2]}
\hlstd{myVars} \hlkwb{=} \hlkwd{c}\hlstd{(}\hlstr{"B0RMSE"}\hlstd{,} \hlstr{"B1RMSE"}\hlstd{,} \hlstr{"B2RMSE"}\hlstd{,} \hlstr{"B0RMSE Rank"}\hlstd{,} \hlstr{"B1RMSE Rank"}\hlstd{,} \hlstr{"B2RMSE Rank"}\hlstd{,}
    \hlstr{"Sample Size"}\hlstd{,} \hlstr{"Error"}\hlstd{,} \hlstr{"True Model"}\hlstd{,} \hlstr{"B0 SpVar"}\hlstd{,} \hlstr{"B1 SpVar"}\hlstd{,} \hlstr{"B2 SpVar"}\hlstd{,}
    \hlstr{"Model Number"}\hlstd{)}
\hlstd{rankData1} \hlkwb{=} \hlkwd{as.data.frame}\hlstd{(}\hlkwd{t}\hlstd{(mcOutput[}\hlstr{"AIC"}\hlstd{, myVars, ]))}
\hlstd{rankData1}\hlopt{$}\hlstd{Metric} \hlkwb{=} \hlstr{"AIC"}
\hlstd{rankData2} \hlkwb{=} \hlkwd{as.data.frame}\hlstd{(}\hlkwd{t}\hlstd{(mcOutput[}\hlstr{"GCV"}\hlstd{, myVars, ]))}
\hlstd{rankData2}\hlopt{$}\hlstd{Metric} \hlkwb{=} \hlstr{"GCV"}
\hlstd{rankData3} \hlkwb{=} \hlkwd{as.data.frame}\hlstd{(}\hlkwd{t}\hlstd{(mcOutput[}\hlstr{"SCV"}\hlstd{, myVars, ]))}
\hlstd{rankData3}\hlopt{$}\hlstd{Metric} \hlkwb{=} \hlstr{"SCV"}
\hlstd{rankData4} \hlkwb{=} \hlkwd{as.data.frame}\hlstd{(}\hlkwd{t}\hlstd{(mcOutput[}\hlstr{"LOOCV"}\hlstd{, myVars, ]))}
\hlstd{rankData4}\hlopt{$}\hlstd{Metric} \hlkwb{=} \hlstr{"LOOCV"}
\hlstd{rankData} \hlkwb{=} \hlkwd{rbind}\hlstd{(rankData1, rankData2, rankData3, rankData4)}
\hlstd{rankData}\hlopt{$}\hlstd{samplesize} \hlkwb{=} \hlstd{rankData[,} \hlstr{"Sample Size"}\hlstd{]}
\hlstd{rankData}\hlopt{$}\hlstd{error} \hlkwb{=} \hlkwd{as.factor}\hlstd{(rankData}\hlopt{$}\hlstd{Error)}
\hlstd{rankData}\hlopt{$}\hlstd{truemodel} \hlkwb{=} \hlkwd{as.factor}\hlstd{(rankData[,} \hlstr{"True Model"}\hlstd{])}
\hlstd{rankData}\hlopt{$}\hlstd{B0sv} \hlkwb{=} \hlkwd{as.factor}\hlstd{(rankData[,} \hlstr{"B0 SpVar"}\hlstd{])}
\hlstd{rankData}\hlopt{$}\hlstd{B1sv} \hlkwb{=} \hlkwd{as.factor}\hlstd{(rankData[,} \hlstr{"B1 SpVar"}\hlstd{])}
\hlstd{rankData}\hlopt{$}\hlstd{B2sv} \hlkwb{=} \hlkwd{as.factor}\hlstd{(rankData[,} \hlstr{"B2 SpVar"}\hlstd{])}
\hlstd{rankData}\hlopt{$}\hlstd{metric} \hlkwb{=} \hlkwd{as.factor}\hlstd{(rankData}\hlopt{$}\hlstd{Metric)}
\hlkwd{names}\hlstd{(rankData)[}\hlkwd{which}\hlstd{(}\hlkwd{names}\hlstd{(rankData)} \hlopt{==} \hlstr{"Model Number"}\hlstd{)]} \hlkwb{=} \hlstr{"selectedmodel"}
\end{alltt}
\end{kframe}
\end{knitrout}


\subsection{RMSE Values}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RMSEregression0} \hlkwb{<-} \hlkwd{lm}\hlstd{(B0RMSE} \hlopt{~} \hlstd{samplesize} \hlopt{+} \hlstd{metric} \hlopt{+} \hlstd{B0sv} \hlopt{+} \hlstd{B1sv} \hlopt{+} \hlstd{B2sv} \hlopt{+} \hlstd{error,}
    \hlkwc{data} \hlstd{= rankData)}
\hlkwd{summary}\hlstd{(RMSEregression0)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = B0RMSE ~ samplesize + metric + B0sv + B1sv + B2sv + 
##     error, data = rankData)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.7206 -0.1046 -0.0168  0.0750  2.6470 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  1.24e-01   1.32e-03   93.81   <2e-16 ***
## samplesize  -3.01e-04   1.04e-06 -290.47   <2e-16 ***
## metricGCV    3.70e-03   9.95e-04    3.72    2e-04 ***
## metricLOOCV  1.04e-02   9.95e-04   10.46   <2e-16 ***
## metricSCV    2.01e-01   9.95e-04  201.63   <2e-16 ***
## B0sv1        2.97e-01   8.61e-04  345.32   <2e-16 ***
## B0sv3        6.45e-01   8.61e-04  748.50   <2e-16 ***
## B1sv1        1.34e-02   8.61e-04   15.56   <2e-16 ***
## B1sv3        6.31e-02   8.61e-04   73.30   <2e-16 ***
## B2sv1        1.36e-02   8.61e-04   15.79   <2e-16 ***
## B2sv3        6.48e-02   8.61e-04   75.24   <2e-16 ***
## error1       1.14e-01   8.61e-04  132.67   <2e-16 ***
## error2       3.12e-01   8.61e-04  362.13   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.179 on 259187 degrees of freedom
## Multiple R-squared:  0.766,	Adjusted R-squared:  0.766 
## F-statistic: 7.09e+04 on 12 and 259187 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RMSEregression1} \hlkwb{<-} \hlkwd{lm}\hlstd{(B1RMSE} \hlopt{~} \hlstd{samplesize} \hlopt{+} \hlstd{metric} \hlopt{+} \hlstd{B0sv} \hlopt{+} \hlstd{B1sv} \hlopt{+} \hlstd{B2sv} \hlopt{+} \hlstd{error,}
    \hlkwc{data} \hlstd{= rankData)}
\hlkwd{summary}\hlstd{(RMSEregression1)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = B1RMSE ~ samplesize + metric + B0sv + B1sv + B2sv + 
##     error, data = rankData)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.866 -0.166 -0.025  0.122  5.309 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  1.73e-01   2.12e-03   81.83  < 2e-16 ***
## samplesize  -4.02e-04   1.66e-06 -242.18  < 2e-16 ***
## metricGCV    1.26e-02   1.59e-03    7.89  3.0e-15 ***
## metricLOOCV  2.13e-02   1.59e-03   13.38  < 2e-16 ***
## metricSCV    1.80e-01   1.59e-03  113.11  < 2e-16 ***
## B0sv1        1.16e-01   1.38e-03   84.16  < 2e-16 ***
## B0sv3        1.84e-01   1.38e-03  133.24  < 2e-16 ***
## B1sv1        1.43e-01   1.38e-03  103.45  < 2e-16 ***
## B1sv3        4.13e-01   1.38e-03  299.84  < 2e-16 ***
## B2sv1        6.25e-03   1.38e-03    4.54  5.6e-06 ***
## B2sv3        1.32e-02   1.38e-03    9.57  < 2e-16 ***
## error1       1.32e-01   1.38e-03   95.95  < 2e-16 ***
## error2       3.69e-01   1.38e-03  267.90  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.286 on 259187 degrees of freedom
## Multiple R-squared:  0.501,	Adjusted R-squared:  0.501 
## F-statistic: 2.17e+04 on 12 and 259187 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RMSEregression2} \hlkwb{<-} \hlkwd{lm}\hlstd{(B2RMSE} \hlopt{~} \hlstd{samplesize} \hlopt{+} \hlstd{metric} \hlopt{+} \hlstd{B0sv} \hlopt{+} \hlstd{B1sv} \hlopt{+} \hlstd{B2sv} \hlopt{+} \hlstd{error,}
    \hlkwc{data} \hlstd{= rankData)}
\hlkwd{summary}\hlstd{(RMSEregression2)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = B2RMSE ~ samplesize + metric + B0sv + B1sv + B2sv + 
##     error, data = rankData)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.901 -0.167 -0.025  0.123  4.371 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  1.73e-01   2.13e-03   81.35  < 2e-16 ***
## samplesize  -4.01e-04   1.67e-06 -240.17  < 2e-16 ***
## metricGCV    1.29e-02   1.60e-03    8.08  6.5e-16 ***
## metricLOOCV  2.21e-02   1.60e-03   13.82  < 2e-16 ***
## metricSCV    1.80e-01   1.60e-03  112.14  < 2e-16 ***
## B0sv1        1.13e-01   1.39e-03   81.25  < 2e-16 ***
## B0sv3        1.82e-01   1.39e-03  131.29  < 2e-16 ***
## B1sv1        8.10e-03   1.39e-03    5.84  5.1e-09 ***
## B1sv3        1.29e-02   1.39e-03    9.32  < 2e-16 ***
## B2sv1        1.43e-01   1.39e-03  103.24  < 2e-16 ***
## B2sv3        4.14e-01   1.39e-03  298.96  < 2e-16 ***
## error1       1.32e-01   1.39e-03   95.41  < 2e-16 ***
## error2       3.67e-01   1.39e-03  265.00  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.288 on 259187 degrees of freedom
## Multiple R-squared:  0.497,	Adjusted R-squared:  0.497 
## F-statistic: 2.14e+04 on 12 and 259187 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}


Now I'd like to add a variable along the lines of ``does the selected model correctly identify whether the variable is non-stationary?''

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{TrueModelBeta0sv} \hlkwb{=} \hlkwd{c}\hlstd{(}\hlnum{2}\hlstd{,} \hlnum{4}\hlstd{,} \hlnum{6}\hlstd{,} \hlnum{8}\hlstd{)}
\hlstd{TrueModelBeta1sv} \hlkwb{=} \hlkwd{c}\hlstd{(}\hlnum{3}\hlstd{,} \hlnum{4}\hlstd{,} \hlnum{7}\hlstd{,} \hlnum{8}\hlstd{)}
\hlstd{TrueModelBeta2sv} \hlkwb{=} \hlnum{5}\hlopt{:}\hlnum{8}
\hlstd{ModelBetaSV.selected.true} \hlkwb{=} \hlkwa{function}\hlstd{(}\hlkwc{TrueModelBetasv}\hlstd{) \{}
    \hlstd{temp} \hlkwb{=} \hlstd{rankData}\hlopt{$}\hlstd{truemodel} \hlopt{%in%} \hlstd{TrueModelBetasv}
    \hlstd{temp2} \hlkwb{=} \hlstd{rankData}\hlopt{$}\hlstd{selectedmodel} \hlopt{%in%} \hlstd{TrueModelBetasv}
    \hlstd{ModelBetaSVCorrect} \hlkwb{<-} \hlstd{temp} \hlopt{==} \hlstd{temp2}
    \hlstd{ModelBetaSVCorrect}
\hlstd{\}}
\hlstd{rankData}\hlopt{$}\hlstd{ModelBeta0svTrue} \hlkwb{=} \hlkwd{ModelBetaSV.selected.true}\hlstd{(TrueModelBeta0sv)}
\hlstd{rankData}\hlopt{$}\hlstd{ModelBeta1svTrue} \hlkwb{=} \hlkwd{ModelBetaSV.selected.true}\hlstd{(TrueModelBeta1sv)}
\hlstd{rankData}\hlopt{$}\hlstd{ModelBeta2svTrue} \hlkwb{=} \hlkwd{ModelBetaSV.selected.true}\hlstd{(TrueModelBeta2sv)}
\end{alltt}
\end{kframe}
\end{knitrout}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RMSEregression0} \hlkwb{<-} \hlkwd{lm}\hlstd{(B0RMSE} \hlopt{~} \hlstd{samplesize} \hlopt{+} \hlstd{metric} \hlopt{+} \hlstd{B0sv} \hlopt{+} \hlstd{B1sv} \hlopt{+} \hlstd{B2sv} \hlopt{+} \hlstd{error} \hlopt{+}
    \hlstd{ModelBeta0svTrue,} \hlkwc{data} \hlstd{= rankData)}
\hlkwd{summary}\hlstd{(RMSEregression0)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = B0RMSE ~ samplesize + metric + B0sv + B1sv + B2sv + 
##     error + ModelBeta0svTrue, data = rankData)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.6612 -0.1027 -0.0178  0.0727  2.6565 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)           1.91e-01   1.48e-03  128.91  < 2e-16 ***
## samplesize           -2.87e-04   1.03e-06 -278.73  < 2e-16 ***
## metricGCV             4.23e-03   9.78e-04    4.33  1.5e-05 ***
## metricLOOCV           1.04e-02   9.78e-04   10.64  < 2e-16 ***
## metricSCV             1.82e-01   9.97e-04  182.76  < 2e-16 ***
## B0sv1                 3.10e-01   8.58e-04  361.75  < 2e-16 ***
## B0sv3                 6.75e-01   9.05e-04  745.99  < 2e-16 ***
## B1sv1                 1.33e-02   8.47e-04   15.66  < 2e-16 ***
## B1sv3                 6.20e-02   8.47e-04   73.18  < 2e-16 ***
## B2sv1                 1.35e-02   8.47e-04   15.89  < 2e-16 ***
## B2sv3                 6.36e-02   8.47e-04   75.08  < 2e-16 ***
## error1                1.09e-01   8.49e-04  128.32  < 2e-16 ***
## error2                2.99e-01   8.58e-04  348.72  < 2e-16 ***
## ModelBeta0svTrueTRUE -9.40e-02   9.96e-04  -94.43  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.176 on 259186 degrees of freedom
## Multiple R-squared:  0.774,	Adjusted R-squared:  0.774 
## F-statistic: 6.84e+04 on 13 and 259186 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RMSEregression1} \hlkwb{<-} \hlkwd{lm}\hlstd{(B1RMSE} \hlopt{~} \hlstd{samplesize} \hlopt{+} \hlstd{metric} \hlopt{+} \hlstd{B0sv} \hlopt{+} \hlstd{B1sv} \hlopt{+} \hlstd{B2sv} \hlopt{+} \hlstd{error} \hlopt{+}
    \hlstd{ModelBeta1svTrue,} \hlkwc{data} \hlstd{= rankData)}
\hlkwd{summary}\hlstd{(RMSEregression1)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = B1RMSE ~ samplesize + metric + B0sv + B1sv + B2sv + 
##     error + ModelBeta1svTrue, data = rankData)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.820 -0.161 -0.026  0.113  5.368 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)           2.60e-01   2.40e-03  108.37  < 2e-16 ***
## samplesize           -3.86e-04   1.66e-06 -232.97  < 2e-16 ***
## metricGCV             1.36e-02   1.57e-03    8.66  < 2e-16 ***
## metricLOOCV           2.37e-02   1.57e-03   15.02  < 2e-16 ***
## metricSCV             1.81e-01   1.57e-03  115.02  < 2e-16 ***
## B0sv1                 1.04e-01   1.37e-03   75.39  < 2e-16 ***
## B0sv3                 1.57e-01   1.41e-03  111.16  < 2e-16 ***
## B1sv1                 9.77e-02   1.49e-03   65.51  < 2e-16 ***
## B1sv3                 3.99e-01   1.38e-03  290.14  < 2e-16 ***
## B2sv1                 5.86e-03   1.36e-03    4.30  1.7e-05 ***
## B2sv3                 1.12e-02   1.36e-03    8.24  < 2e-16 ***
## error1                1.26e-01   1.37e-03   91.92  < 2e-16 ***
## error2                3.57e-01   1.37e-03  259.78  < 2e-16 ***
## ModelBeta1svTrueTRUE -9.59e-02   1.29e-03  -74.17  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.283 on 259186 degrees of freedom
## Multiple R-squared:  0.512,	Adjusted R-squared:  0.512 
## F-statistic: 2.09e+04 on 13 and 259186 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RMSEregression2} \hlkwb{<-} \hlkwd{lm}\hlstd{(B2RMSE} \hlopt{~} \hlstd{samplesize} \hlopt{+} \hlstd{metric} \hlopt{+} \hlstd{B0sv} \hlopt{+} \hlstd{B1sv} \hlopt{+} \hlstd{B2sv} \hlopt{+} \hlstd{error} \hlopt{+}
    \hlstd{ModelBeta2svTrue,} \hlkwc{data} \hlstd{= rankData)}
\hlkwd{summary}\hlstd{(RMSEregression2)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = B2RMSE ~ samplesize + metric + B0sv + B1sv + B2sv + 
##     error + ModelBeta2svTrue, data = rankData)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.857 -0.162 -0.026  0.113  4.462 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)           2.60e-01   2.41e-03  107.81  < 2e-16 ***
## samplesize           -3.85e-04   1.67e-06 -231.09  < 2e-16 ***
## metricGCV             1.40e-02   1.58e-03    8.84  < 2e-16 ***
## metricLOOCV           2.45e-02   1.58e-03   15.47  < 2e-16 ***
## metricSCV             1.81e-01   1.58e-03  114.11  < 2e-16 ***
## B0sv1                 1.00e-01   1.38e-03   72.30  < 2e-16 ***
## B0sv3                 1.55e-01   1.42e-03  109.58  < 2e-16 ***
## B1sv1                 8.18e-03   1.37e-03    5.96  2.5e-09 ***
## B1sv3                 1.15e-02   1.37e-03    8.38  < 2e-16 ***
## B2sv1                 9.82e-02   1.50e-03   65.45  < 2e-16 ***
## B2sv3                 4.01e-01   1.38e-03  289.99  < 2e-16 ***
## error1                1.26e-01   1.37e-03   91.35  < 2e-16 ***
## error2                3.55e-01   1.38e-03  257.01  < 2e-16 ***
## ModelBeta2svTrueTRUE -9.63e-02   1.30e-03  -74.09  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.285 on 259186 degrees of freedom
## Multiple R-squared:  0.508,	Adjusted R-squared:  0.508 
## F-statistic: 2.06e+04 on 13 and 259186 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}


Now add all three:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RMSEregression0} \hlkwb{<-} \hlkwd{lm}\hlstd{(B0RMSE} \hlopt{~} \hlstd{samplesize} \hlopt{+} \hlstd{metric} \hlopt{+} \hlstd{B0sv} \hlopt{+} \hlstd{B1sv} \hlopt{+} \hlstd{B2sv} \hlopt{+} \hlstd{error} \hlopt{+}
    \hlstd{ModelBeta0svTrue,} \hlkwc{data} \hlstd{= rankData)}
\hlkwd{summary}\hlstd{(RMSEregression0)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = B0RMSE ~ samplesize + metric + B0sv + B1sv + B2sv + 
##     error + ModelBeta0svTrue, data = rankData)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.6612 -0.1027 -0.0178  0.0727  2.6565 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)           1.91e-01   1.48e-03  128.91  < 2e-16 ***
## samplesize           -2.87e-04   1.03e-06 -278.73  < 2e-16 ***
## metricGCV             4.23e-03   9.78e-04    4.33  1.5e-05 ***
## metricLOOCV           1.04e-02   9.78e-04   10.64  < 2e-16 ***
## metricSCV             1.82e-01   9.97e-04  182.76  < 2e-16 ***
## B0sv1                 3.10e-01   8.58e-04  361.75  < 2e-16 ***
## B0sv3                 6.75e-01   9.05e-04  745.99  < 2e-16 ***
## B1sv1                 1.33e-02   8.47e-04   15.66  < 2e-16 ***
## B1sv3                 6.20e-02   8.47e-04   73.18  < 2e-16 ***
## B2sv1                 1.35e-02   8.47e-04   15.89  < 2e-16 ***
## B2sv3                 6.36e-02   8.47e-04   75.08  < 2e-16 ***
## error1                1.09e-01   8.49e-04  128.32  < 2e-16 ***
## error2                2.99e-01   8.58e-04  348.72  < 2e-16 ***
## ModelBeta0svTrueTRUE -9.40e-02   9.96e-04  -94.43  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.176 on 259186 degrees of freedom
## Multiple R-squared:  0.774,	Adjusted R-squared:  0.774 
## F-statistic: 6.84e+04 on 13 and 259186 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RMSEregression1} \hlkwb{<-} \hlkwd{lm}\hlstd{(B1RMSE} \hlopt{~} \hlstd{samplesize} \hlopt{+} \hlstd{metric} \hlopt{+} \hlstd{B0sv} \hlopt{+} \hlstd{B1sv} \hlopt{+} \hlstd{B2sv} \hlopt{+} \hlstd{error} \hlopt{+}
    \hlstd{ModelBeta1svTrue,} \hlkwc{data} \hlstd{= rankData)}
\hlkwd{summary}\hlstd{(RMSEregression1)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = B1RMSE ~ samplesize + metric + B0sv + B1sv + B2sv + 
##     error + ModelBeta1svTrue, data = rankData)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.820 -0.161 -0.026  0.113  5.368 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)           2.60e-01   2.40e-03  108.37  < 2e-16 ***
## samplesize           -3.86e-04   1.66e-06 -232.97  < 2e-16 ***
## metricGCV             1.36e-02   1.57e-03    8.66  < 2e-16 ***
## metricLOOCV           2.37e-02   1.57e-03   15.02  < 2e-16 ***
## metricSCV             1.81e-01   1.57e-03  115.02  < 2e-16 ***
## B0sv1                 1.04e-01   1.37e-03   75.39  < 2e-16 ***
## B0sv3                 1.57e-01   1.41e-03  111.16  < 2e-16 ***
## B1sv1                 9.77e-02   1.49e-03   65.51  < 2e-16 ***
## B1sv3                 3.99e-01   1.38e-03  290.14  < 2e-16 ***
## B2sv1                 5.86e-03   1.36e-03    4.30  1.7e-05 ***
## B2sv3                 1.12e-02   1.36e-03    8.24  < 2e-16 ***
## error1                1.26e-01   1.37e-03   91.92  < 2e-16 ***
## error2                3.57e-01   1.37e-03  259.78  < 2e-16 ***
## ModelBeta1svTrueTRUE -9.59e-02   1.29e-03  -74.17  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.283 on 259186 degrees of freedom
## Multiple R-squared:  0.512,	Adjusted R-squared:  0.512 
## F-statistic: 2.09e+04 on 13 and 259186 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RMSEregression2} \hlkwb{<-} \hlkwd{lm}\hlstd{(B2RMSE} \hlopt{~} \hlstd{samplesize} \hlopt{+} \hlstd{metric} \hlopt{+} \hlstd{B0sv} \hlopt{+} \hlstd{B1sv} \hlopt{+} \hlstd{B2sv} \hlopt{+} \hlstd{error} \hlopt{+}
    \hlstd{ModelBeta2svTrue,} \hlkwc{data} \hlstd{= rankData)}
\hlkwd{summary}\hlstd{(RMSEregression2)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = B2RMSE ~ samplesize + metric + B0sv + B1sv + B2sv + 
##     error + ModelBeta2svTrue, data = rankData)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.857 -0.162 -0.026  0.113  4.462 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)           2.60e-01   2.41e-03  107.81  < 2e-16 ***
## samplesize           -3.85e-04   1.67e-06 -231.09  < 2e-16 ***
## metricGCV             1.40e-02   1.58e-03    8.84  < 2e-16 ***
## metricLOOCV           2.45e-02   1.58e-03   15.47  < 2e-16 ***
## metricSCV             1.81e-01   1.58e-03  114.11  < 2e-16 ***
## B0sv1                 1.00e-01   1.38e-03   72.30  < 2e-16 ***
## B0sv3                 1.55e-01   1.42e-03  109.58  < 2e-16 ***
## B1sv1                 8.18e-03   1.37e-03    5.96  2.5e-09 ***
## B1sv3                 1.15e-02   1.37e-03    8.38  < 2e-16 ***
## B2sv1                 9.82e-02   1.50e-03   65.45  < 2e-16 ***
## B2sv3                 4.01e-01   1.38e-03  289.99  < 2e-16 ***
## error1                1.26e-01   1.37e-03   91.35  < 2e-16 ***
## error2                3.55e-01   1.38e-03  257.01  < 2e-16 ***
## ModelBeta2svTrueTRUE -9.63e-02   1.30e-03  -74.09  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.285 on 259186 degrees of freedom
## Multiple R-squared:  0.508,	Adjusted R-squared:  0.508 
## F-statistic: 2.06e+04 on 13 and 259186 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}


\subsection{RMSE Rank}

\subsection{RMSE Rank Proportion}

\end{document}

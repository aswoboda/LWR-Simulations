% setwd("SpecificationSims/Writeup/")
\documentclass{article}
\usepackage[height = 9in, top = 1in, width = 6.3 in]{geometry}
\usepackage{verbatim, amsmath, amsthm, amssymb}

\title{A Monte Carlo Investigation of Locally Weighted Regression}
\author{Aaron Swoboda and Sam Carruthers}
\begin{document}

\maketitle

This document writes up the results of the recent run of \texttt{uberScript.R}. It contains the following code:

<<eval=FALSE, tidy=FALSE>>=
# set our simulation parameters
Replications = 100
sample.size = c(50, 100, 200, 500, 1000)
error.sd = c(2, 4, 6)
B1.spatial.var = c(0, .1, .2, .3)
B2.spatial.var = c(0, .1, .2, .3)

# now march through the different parameter combinations running the simulations

for( i in 1:meta.sim.num) { 
  start = Sys.time()
  simRepOut = simulationReplicator(Replications, sim.parameters[i, ], MC = TRUE)
  simOut = simRepReorganizer(simRepOut)
  
  R2Output[as.character(sim.parameters[i, "sample.size"]),
           as.character(sim.parameters[i, "error.sd"]),
           as.character(sim.parameters[i, "B1.spatial.var"]),
           as.character(sim.parameters[i, "B2.spatial.var"]), , ] = simOut[[1]]
  
  MetricOutput[as.character(sim.parameters[i, "sample.size"]),
               as.character(sim.parameters[i, "error.sd"]),
               as.character(sim.parameters[i, "B1.spatial.var"]),
               as.character(sim.parameters[i, "B2.spatial.var"]), , , ] = simOut[[2]]
  end = Sys.time()

  print(paste("For loop", i,"of", meta.sim.num))
  print(round(difftime(end, start, units = "m"), 2))
  save(R2Output, MetricOutput, file = "SpecificationSims/uberScriptOutput.RData")
}
@

I'm not going to run that code here (it took almost a month to run on the R Server), but let's load up the results and start to look at them. Or at least come up with some questions to ask of the data and a plan for the future.
\newpage
<<cache=TRUE>>=
load("../Data/uberScriptOutput20120919.RData")
dimnames(MetricOutput)
dimnames(R2Output)
@

So, we ran some simulations, varying the sample size of the data set, the standard deviation of the error term in the model and the degree of spatial variation in the model coefficients. 

Each simulation was conducted as follows:
\begin{enumerate}
\item Grab the simulation parameters.
\item Generate the data according to the model and parameters. 
\item Choose a number of observations to include in the Locally Weighted Regression.
\item Run Locally Weighted Regression on the data using the chosen bandwidth for each observation within the dataset.
\item Calculate a number of model metrics for each bandwidth
\item Repeat previous two steps for a number of bandwidths, ranging from only 5 data points to a model approaching a global Ordinary Least Squares model (in our case, we still had declining weights based on distance, but all observations received positive weight in the regresssion).
\item Collect data on each metric when each metric is optimized. For instance, when we choose the bandwidth associated with the lowest GCV score, what are the other metric values ($\beta$ RMSEs, etc.)
\end{enumerate}

We kept track of the following model performance metrics, the pseudo $R^2$ of the model results, the correlation between the $\hat{\beta}$ and the true $\beta$, the percent of the observations for which we can reject the null hypothesis that $\hat{\beta}=\beta$, cross validation scores (leave one out, generalized, and standardized according to Paez), lastly the AIC score.

\subsection{Data Generation Process}

The Data Generation Process is achieved using the \texttt{DataGen} function, the code for which is given below. 
<<>>=
source("../SimFunctions.R")
DataGen
@

The dependent variable is produced as follows:
\begin{equation}
Y = \beta _0 + \beta _1(location) X_1 + \beta _2(location) X_2 + error
\end{equation}
where $error \sim n(0, \sigma ^2)$. Each observation is located within a geographic coordinate system $(east, north)$ where both $east$ and $north$ values are $\sim u(0, 10)$. The functions determining $\beta _1$ and $\beta _2$ are :
\begin{eqnarray}
\beta _1 (east, north) &=& 1 + Bsv1 * north - 5*Bsv1 \\
\beta _2 (east, north) &=& 1 + Bsv2 * east - 5*Bsv2
\end{eqnarray}
In our simulations we let $Bsv_i$ vary $\{0, 0.1, 0.2, 0.3\}$, thus the relationship between $\beta$s and location can be visualized as:

<<fig = T, fig.height= 4, fig.width=7>>=
east = north = 0:10
BetaFunc = function(x, Bsv) {
 1 + Bsv * x - 5*Bsv
}
par(mfrow = c(1, 2))
plot(north, BetaFunc(north, .3), type = "l",
     xlab = "north",
     ylab = "True Beta",
     main = expression(paste("True ", beta[1], " over Space")))
lines(north, BetaFunc(north, .2), col = "red")
lines(north, BetaFunc(north, .1), col = "blue")
lines(north, BetaFunc(north, 0), col = "orange")
text(rep(0, 4), seq(.925, -.5, length = 4), paste("Bsv1=",(0:3)/10), pos = 4,
     col = c("orange", "blue", "red", "black"), cex = .7, offset = 0)

plot(east, BetaFunc(east, .3), type = "l",
     xlab = "east",
     ylab = "True Beta",
     main = expression(paste("True ", beta[2], " over Space")))
lines(east, BetaFunc(east, .2), col = "red")
lines(east, BetaFunc(east, .1), col = "blue")
lines(east, BetaFunc(east, 0), col = "orange")
text(rep(0, 4), seq(.925, -.5, length = 4), paste("Bsv2=",(0:3)/10), pos = 4,
     col = c("orange", "blue", "red", "black"), cex = .7, offset = 0)
@

Our simulations include data generation processes in which:
\begin{enumerate}
\item neither coefficient varies over space ($Bsv_1 = 0$ \& $Bsv_2 = 0$)
\item both coefficients vary over space ($Bsv_1 \neq 0$ \& $Bsv_2 \neq 0$)
\item only one coefficient varies over space ($Bsv_1 = 0$ \& $Bsv_2 \neq 0$ OR $Bsv_1 \neq 0$ \& $Bsv_2 = 0$)
\end{enumerate}

Each simulation can be characterized by our selection of four data generation parameters,
\begin{itemize}
\item sample size $\{50, 200, 500, 1000\}$
\item variance of the error term $\{2^2, 4^2, 6^2\}$
\item degree of spatial variation in $\beta _1$  $\{0, .1, .2, .3\}$
\item degree of spatial variation in $\beta _2$  $\{0, .1, .2, .3\}$
\end{itemize}

\section{Research Questions}
What do we want to know about LWR?

\begin{enumerate}
  \item Are there systematic differences in the bandwidth size selected by different techniques? How do LOOCV, Standardaized CV, Generalize CV, and the AICc compare?
  \item What sort of spatial variation in the coefficients is necessary relative to the error to need LWR?
  \item If there is no spatial relationship, will LWR default back to global OLS?
\end{enumerate}

\section{Applying Locally Weighted Regression}

After generating the data, we applied Locally Weighted Regression and calculated numerous diagnostics in order to measure the performance of the regression technique.

Locally Weighted Regression (LWR) is an estimation strategy allowing non-stationary model parameters. A vector of regression parameters is estimated using Equation~\eqref{eq:LWR} for each location within the dataset, 
\begin{equation}\label{eq:LWR}
\hat{\beta}_{location_i} =(X^TW_{location_i}X)^{-1}X^TW_{location_i}Y,
\end{equation}
where $X$ is the standard $n$ x $m$ data matrix, $Y$ the $n$ x $1$ vector of dependent variable values, and $W_{location_i}$ is an $n$ x $n$ weights matrix. We construct the weights matrix for a given location to give positive weights to the $k$-nearest data points, with weights declining according to a bi-square function as distances increase.  Specifically, we create the weights matrix with zeros on the off-diagonal and calculate the $jj$th diagonal element as,
\begin{equation}\label{eq:bisquare}
w_{ij}= 
\begin{cases} \left[1-\left(\frac{d_{ij}}{d_{ik}}\right)^2\right]^2 & \text{if $d_{ij}\leq d_{ik}$} \\
0 &\text{if $d_{ij} > d_{ik}$}
\end{cases}
\end{equation}
where $d_{ij}$ is the distance between observations $i$ and $j$, and $d_{ik}$ is the distance to the $k$th nearest observation to observation $i$.

\subsection{Cross-Validation}
Theory does not provide guidance as to how many observations should receive positive weights in the local regression and must be determined by the researcher for the problem at hand. Typically, the $k$ parameter is determined by minimizing a cross-validation metric. This research aims to systematically compare the performance of four different cross-validation metrics used in LWR research.
\begin{enumerate}
\item Leave-One-Out Cross-Validation
\item Generalized Cross-Validation 
\item Standardized Cross-Validation
\item Akaike Information Criterion
\end{enumerate}

Does choosing the optimal number of observations to include in the LWR through these four strategies yield similar results? If there are differences, are there patterns in how they are different?

\subsection{Leave-One Out Cross-Validation}

\begin{equation}
\sum (y - \hat{y}_{-i})^2
\end{equation}

\subsection{Generalized Cross-Validation Score}
\begin{equation}\label{eq:GCV}
  n*\sum_{i=1}^{n}\frac{(y_i-\hat{y}_i)^2}{(n-v_1)^2}, 
  \end{equation}
where $y_i$ is the dependent variable value, $\hat{y}_i$ is the predicted dependent variable value for observation $i$, and $v_1$ is the ``effective number of model parameters.''\footnote{
  $v_1=$tr(\textbf{S}), where the matrix \textbf{S} is the ``hat matrix'' which maps $y$ onto $\hat{y}$,
\begin{equation*}
  \hat{y}=\textbf{S}y,
  \end{equation*}
  and each row of \textbf{S}, $r_i$ is given by:
  \begin{equation*}
    r_i=X_i(X^TW(location_i)X)^{-1}X^TW(location_i).
    \end{equation*}
}
In an LWR model, the number of parameters to be estimated is no longer equal to the number of variables included because we allow the regression coefficients to vary over space. The GCV score calculates the ``effective'' number of model parameters, $v_1$, and penalizes the model for increasing the number of parameters without sufficient reduction in model accuracy. Taking the square root of Equation~\eqref{eq:GCV} and rearranging yields,
\begin{equation}
  \sqrt{GCV}=\sqrt{\frac{n}{n-v_1}} \sqrt{\frac{\textrm{Sum of Squared Residuals}}{n-v_1}},
\end{equation}
which approaches $\hat{\sigma}$ as $v_1$ approaches $m$ for large $n$. Henceforth, throughout the paper we report the square root of \eqref{eq:GCV} because of its similarity to $\hat{\sigma}$.  

\subsection{Row Standardized Cross-Validation}

Something about Paez, who wanted a CV score that was more robust to outliers.

\begin{equation}\label{eq:SCV}
\frac{\sum (y - y_{-i})^2} {\sum y}
\end{equation}

\subsection{Akaike Information Criterion}

\begin{equation}\label{eq:AIC}
  2*n*ln(\hat{\sigma}) + n*ln(2*\pi) + 
    n*\frac{n + v_1}{n - 2 - v_1}
    \end{equation}

\end{document}